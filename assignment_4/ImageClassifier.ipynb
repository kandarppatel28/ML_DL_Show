{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#importing all te req lib\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras import backend as K\nfrom keras.preprocessing import image\nimport numpy as np",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using TensorFlow backend.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# dimensions of our images.\nimg_width, img_height = 150, 150\n\n#defining the data directories\ntrain_data_dir= 'data/train'\nvalidation_data_dir= 'data/validation'\nn_training_sample= 1580\nn_validation_sample= 385\nepochs=10\nbatch_size=64\n",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "if K.image_data_format() == 'channels_first':\n    input_shape = (3, img_width, img_height)\nelse:\n    input_shape = (img_width, img_height, 3)",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# this is the augmentation configuration we will use for training\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\n# this is the augmentation configuration we will use for testing:\n# only rescaling\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='categorical')\n\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='categorical')",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Found 1580 images belonging to 4 classes.\nFound 385 images belonging to 4 classes.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#defining the model\nmodel = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n                                    tf.keras.layers.Dense(64, activation=tf.nn.relu), \n                                    tf.keras.layers.Dense(8, activation=tf.nn.relu),\n                                    tf.keras.layers.Dense(4, activation=tf.nn.softmax)])",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#defining the optimizer and metrics\nmodel.compile(optimizer = tf.optimizers.Adam(),\n              loss = 'categorical_crossentropy',\n              metrics=['accuracy'])\n",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model.fit_generator(\n    train_generator,\n    steps_per_epoch=n_training_sample // batch_size,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=n_validation_sample // batch_size)",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Epoch 1/10\nWARNING:tensorflow:From /home/nbuser/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n24/24 [==============================] - 369s 15s/step - loss: 11.3269 - accuracy: 0.2657 - val_loss: 11.5429 - val_accuracy: 0.2839\nEpoch 2/10\n24/24 [==============================] - 307s 13s/step - loss: 11.9312 - accuracy: 0.2608 - val_loss: 11.5429 - val_accuracy: 0.2839\nEpoch 3/10\n24/24 [==============================] - 289s 12s/step - loss: 12.0046 - accuracy: 0.2503 - val_loss: 11.5429 - val_accuracy: 0.2839\nEpoch 4/10\n24/24 [==============================] - 259s 11s/step - loss: 12.0748 - accuracy: 0.2394 - val_loss: 11.5429 - val_accuracy: 0.2839\nEpoch 5/10\n24/24 [==============================] - 271s 11s/step - loss: 12.1411 - accuracy: 0.2466 - val_loss: 11.5429 - val_accuracy: 0.2839\nEpoch 6/10\n24/24 [==============================] - 242s 10s/step - loss: 11.7329 - accuracy: 0.2893 - val_loss: 11.5429 - val_accuracy: 0.2839\nEpoch 7/10\n24/24 [==============================] - 238s 10s/step - loss: 11.9462 - accuracy: 0.2522 - val_loss: 11.5429 - val_accuracy: 0.2839\nEpoch 8/10\n24/24 [==============================] - 253s 11s/step - loss: 12.2040 - accuracy: 0.2331 - val_loss: 11.5429 - val_accuracy: 0.2839\nEpoch 9/10\n24/24 [==============================] - 246s 10s/step - loss: 11.9086 - accuracy: 0.2718 - val_loss: 11.5429 - val_accuracy: 0.2839\nEpoch 10/10\n24/24 [==============================] - 257s 11s/step - loss: 11.8654 - accuracy: 0.2617 - val_loss: 11.5429 - val_accuracy: 0.2839\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fbc841e0128>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#testing the model\npred= image.load_img('data/test/test/1_2.jpg', target_size=(150,150))\npred=image.img_to_array(pred)\npred= np.expand_dims(pred, axis=0)\nresult= model.predict(pred)[0]\nclasses = validation_generator.class_indices\npredicted_class = None\nfor (c,i) in classes.items():\n    if(result[i] == 1):\n        predicted_class = c\n        break\nprint('Model predicted ' + str(predicted_class))",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Model predicted 3\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(model.predict(pred)) ",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[0. 0. 1. 0.]]\n",
          "name": "stdout"
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}