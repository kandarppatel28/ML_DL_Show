{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#importing lib\nimport numpy as np\nimport pandas as pd",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#importing data\n#For better distrtibution of data in train and test set I have splited each class into 9:1 ratio and then combined them\n#This will give better result\ndataset_0 = pd.read_csv(\"datasets_0.csv\")\ndataset_1 = pd.read_csv(\"datasets_1.csv\")\ndataset_2 = pd.read_csv(\"datasets_2.csv\")\ndataset_3 = pd.read_csv(\"datasets_3.csv\")",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#define X & Y\nX_0 = dataset_0.iloc[:,0:-1].values\nY_0 = dataset_0.iloc[:,-1].values\nX_1 = dataset_1.iloc[:,0:-1].values\nY_1 = dataset_1.iloc[:,-1].values\nX_2 = dataset_2.iloc[:,0:-1].values\nY_2 = dataset_2.iloc[:,-1].values\nX_3 = dataset_3.iloc[:,0:-1].values\nY_3 = dataset_3.iloc[:,-1].values\n",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#split \nfrom sklearn.model_selection import train_test_split\nX_0_train, X_0_test, Y_0_train, Y_0_test= train_test_split(X_0,Y_0, test_size=0.1)\nX_1_train, X_1_test, Y_1_train, Y_1_test= train_test_split(X_1,Y_1, test_size=0.1)\nX_2_train, X_2_test, Y_2_train, Y_2_test= train_test_split(X_2,Y_2, test_size=0.1)\nX_3_train, X_3_test, Y_3_train, Y_3_test= train_test_split(X_3,Y_3, test_size=0.1)\n\nX_train = np.concatenate((X_0_train, X_1_train, X_2_train, X_3_train))\nX_test = np.concatenate((X_0_test, X_1_test, X_2_test, X_3_test))\nY_train = np.concatenate((Y_0_train, Y_1_train, Y_2_train, Y_3_train))\nY_test = np.concatenate((Y_0_test, Y_1_test, Y_2_test, Y_3_test))",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "results = {}\n## Calculate Confision Matrix and F1 Score\ndef cal_result(Y_test, Y_pred):\n    from sklearn import metrics\n    confusionMatrix = metrics.confusion_matrix(Y_test, Y_pred)\n    f1 = metrics.f1_score(Y_test, Y_pred, average='micro')\n    accuracy = metrics.accuracy_score(Y_test, Y_pred)\n    return { 'confusionMatrix' : confusionMatrix, 'f1': f1, 'accuracy': accuracy}",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.linear_model import LogisticRegression\nlogclass= LogisticRegression()\nlogclass.fit(X_train, Y_train)\nY_pred_logistic=logclass.predict(X_test)\nresults['Logistic Regression'] = cal_result(Y_test, Y_pred_logistic)\nprint(results['Logistic Regression'])",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n  \"this warning.\", FutureWarning)\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "{'confusionMatrix': array([[136,  45,  60,  50],\n       [ 42,  84,  85,  80],\n       [ 76,  77,  79,  63],\n       [ 65,  75,  69,  84]]), 'f1': 0.32735042735042735, 'accuracy': 0.32735042735042735}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.neighbors import KNeighborsClassifier\nknn= KNeighborsClassifier()\nknn.fit(X_train, Y_train)\nY_pred_knn= knn.predict(X_test)\nresults['KNN Classifier'] = cal_result(Y_test, Y_pred_knn)\nprint(results['KNN Classifier'])",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "{'confusionMatrix': array([[258,  20,   7,   6],\n       [  0, 259,   2,  30],\n       [  0, 119,  55, 121],\n       [  1,  69,   6, 217]]), 'f1': 0.6743589743589744, 'accuracy': 0.6743589743589744}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.tree import DecisionTreeClassifier\n\n## Complete the code\ndtc= DecisionTreeClassifier()\ndtc.fit(X_train, Y_train)\nY_pred_decision= dtc.predict(X_test)\nresults['Decision Tree'] = cal_result(Y_test, Y_pred_decision)\nprint(results['Decision Tree'])",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "{'confusionMatrix': array([[252,   5,  13,  21],\n       [  1, 233,  24,  33],\n       [  8,  21, 229,  37],\n       [ 20,  31,  22, 220]]), 'f1': 0.7982905982905982, 'accuracy': 0.7982905982905983}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier\n\n## Complete the code\nrfc= RandomForestClassifier()\nrfc.fit(X_train, Y_train)\nY_pred_random= rfc.predict(X_test)\nresults['Random Forest'] = cal_result(Y_test, Y_pred_random)\nprint(results['Random Forest'])",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "{'confusionMatrix': array([[281,   1,   5,   4],\n       [  0, 260,  13,  18],\n       [  6,   4, 271,  14],\n       [ 19,  14,  14, 246]]), 'f1': 0.9042735042735042, 'accuracy': 0.9042735042735043}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "result = results.values()\ndef get_accuracy(res):\n    return res['accuracy']\nmax_accuracy = (max(result, key=get_accuracy))['accuracy']\nprint('Max Accuracy: ' + str(max_accuracy))\n\nprint('\\nBest Models:')\nfor (method, res) in results.items():\n    if(res['accuracy'] == max_accuracy):\n        print(method)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Max Accuracy: 0.9042735042735043\n\nBest Models:\nRandom Forest\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}